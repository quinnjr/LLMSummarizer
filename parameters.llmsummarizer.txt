# LLMSummarizer Plugin Parameters
# Uses Ollama for local LLM inference
#
# Prerequisites:
#   1. Install Ollama: https://ollama.com
#   2. The plugin will auto-start the server if needed
#   3. Models are auto-downloaded if not available

# Input files (from other pipeline steps)
feature_importance	CSV/shap_feature_importance.csv
cv_results	CSV/cv_results.csv
# de_results	CSV/de_results.csv
# cluster_results	CSV/clusters.csv
# model_metrics	CSV/model_metrics.csv

# ============================================================================
# DOMAIN CONFIGURATION
# ============================================================================
# Research domain for context-specific prompts and RAG database
# Available built-in domains:
#   - parkinsons  : Parkinson's disease research
#   - alzheimers  : Alzheimer's disease research
#   - cancer      : Cancer genomics
#   - microbiome  : Microbiome analysis
#   - generic     : General multi-omics (no domain-specific context)
#   - custom      : User-defined domain (see custom_domain_* parameters below)
#
# Default: generic
domain	parkinsons

# ============================================================================
# CUSTOM DOMAIN CONFIGURATION (only used when domain=custom)
# ============================================================================
# custom_domain_name	My Research Area
# custom_domain_description	Multi-omics analysis for my research
# custom_domain_expert_role	bioinformatics expert specializing in my field
# custom_domain_research_focus	identifying biomarkers and mechanisms
# custom_domain_feature_suffix	my disease
# custom_domain_collection	my_findings
# custom_domain_db_path	data/my_literature_db
# custom_domain_archive_pattern	my_literature_db
# custom_domain_summary_title	My Analysis Summary
# custom_domain_summary_subtitle	Biomarker Discovery
# custom_domain_context_queries	query1,query2,query3

# ============================================================================
# LLM MODEL CONFIGURATION
# ============================================================================
# Set to "auto" or leave commented out for automatic hardware-based selection
# The plugin will:
#   1. Detect your CPU, RAM, and GPU (NVIDIA/AMD/Apple Silicon)
#   2. Check which models are already downloaded
#   3. Select the best model for your hardware
#   4. Download it automatically if needed
#
# Manual options: llama3.1:70b, llama3.1:8b, llama3:8b, mistral:7b, 
#                 phi3:medium, phi3:mini, gemma2:2b, tinyllama:1.1b
model_name	auto

# Generation parameters
temperature	0.3
max_tokens	1024

# ============================================================================
# RAG (Retrieval-Augmented Generation) SETTINGS
# ============================================================================
# Enable RAG to augment summaries with literature findings
use_rag	true

# Path to literature vector database
# Default is determined by domain (e.g., data/pd_literature_db for parkinsons)
# Uncomment to override:
# literature_db	data/pd_literature_db

# Collection name within the database
# Default is determined by domain (e.g., pd_findings for parkinsons)
# Uncomment to override:
# rag_collection	pd_findings

# Auto-download RAG database from GitHub releases if not present
rag_auto_download	true

# GitHub repo for RAG database (auto-detected from git remote if not set)
# rag_repo	owner/LLMSummarizer
